---
# An instance of the Experience widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: blank

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 20

title: News 
subtitle: 

# Date format for experience
#   Refer to https://wowchemy.com/docs/customization/#date-format
date_format: Jan 2006

design:
  columns: '1'
---

- **2022-07-08**. Our [comprehensive survey](publication/aire2022deep/) on Deep Learning Based Single Sample Per Person Face Recognition is now published in [*Artificial Intelligence Review*](https://link.springer.com/article/10.1007/s10462-022-10240-2) (Impact Factor=9.588). 
<br /><br />
- **2022-06-29**. My graduation thesis _"Music-driven Conducting Motion Generation based on Motion Decomposition and Self-supervised Cross-modal Perceptual Loss"_ 《基于动态频域分解与跨模态感知的乐队指挥动作生成系统》, previously awarded as Outstanding Graduation Thesis of HHU (河海大学优秀毕业论文), is now awarded as the [First Class of Outstanding Graduation Thesis of Jiangsu Province (江苏省优秀毕业论文一等奖)](http://jyt.jiangsu.gov.cn/art/2022/6/29/art_58320_10520413.html) !
<br /><br />
- **2022-06-23**. Our paper [_"Prototypical Contrastive Language Image Pretraining"_](publication/arxiv2022prototypical/) is finished at Megvii Technology. The [[preprint]](https://arxiv.org/abs/2206.10996) and [[codes]](https://github.com/megvii-research/protoclip) are now available. We developed a prototype-based approach for improved vision language pretraining, which achieved an +5.81% ImageNet linear probing improvement and an +2.01% ImageNet zero-shot classification improvement compared to CLIP.
<br /><br />
- **2022-03-10**. Our paper [_"Self-Supervised Music Motion Synchronization Learning for Music-Driven Conducting Motion Generation"_](publication/jcst2022self/) is accepted by SCI (and CCF-B) indexed journal [Journal of Computer Science and Technology (JCST)](https://www.springer.com/journal/11390). The [ConductorMotion100](https://github.com/ChenDelong1999/VirtualConductor) dataset has been made public as a track of [The 1st Prospective Cup Meta-Intelligent Data Challenge](http://prospective.tocenet.org/)（首届国际“远见杯”元智能数据挑战大赛）hold by [Jiangsu Computer Society](https://www.jscs.org.cn/x1.php?id=770)（江苏省计算机学会）.
<br /><br />
- **2021-09-22**. I begin to work at [MEGVII Technology](https://megvii.com/) (旷视研究院) as a research intern. My research project is related to multimodal self-supervised learning and CLIP-style vision-language pretraining.
<br /><br />
- **2021-08-21**. I received a Best Demo Award from [ICME\'21](http://2021.ieeeicme.org/2021.ieeeicme.org/best_demo_awards.html), a Best Dataset Paper Award from [LTDL workshop](https://ltdl-ijcai21.github.io/submission.html) at IJCAI\'21, and a Best Presentation Award from [BDAI\'21](http://www.bdai.net/2021.html).
<br /><br />
- **2021-07-01**. I received my B.S. degree in computer science from [Hohai University](https://en.hhu.edu.cn/) and begin to work as research assistant at [Fan Liu's Lab](https://www.researchgate.net/lab/Fan-Liu-Lab-2).
<br /><br />
- **1999-03-19**. I was born in Shunde, Guangdong（广东，顺德）, which has a lot of delicious food.

